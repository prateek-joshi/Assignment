{"cells":[{"cell_type":"markdown","metadata":{},"source":["# CarScan Task 2.1 - Damage Classifier\n","<b>Note:</b> The following notebook was executed on Kaggle playground, and hence does not include code for downloading the dataset seperately. Some of the code may be specific to the Kaggle environment.\n","\n","This notebook trains a model for classifying vehicles' images as damaged and not damaged."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:18.441143Z","iopub.status.busy":"2022-01-06T17:13:18.440786Z","iopub.status.idle":"2022-01-06T17:13:19.809141Z","shell.execute_reply":"2022-01-06T17:13:19.808396Z","shell.execute_reply.started":"2022-01-06T17:13:18.441049Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import cv2\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:20.450066Z","iopub.status.busy":"2022-01-06T17:13:20.449801Z","iopub.status.idle":"2022-01-06T17:13:20.455693Z","shell.execute_reply":"2022-01-06T17:13:20.455028Z","shell.execute_reply.started":"2022-01-06T17:13:20.450036Z"},"trusted":true},"outputs":[],"source":["# change current working directory as kaggle is weird\n","# import os\n","\n","# os.chdir('../input/car-damage-detection')\n","# os.getcwd()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:21.385891Z","iopub.status.busy":"2022-01-06T17:13:21.385189Z","iopub.status.idle":"2022-01-06T17:13:21.751189Z","shell.execute_reply":"2022-01-06T17:13:21.750482Z","shell.execute_reply.started":"2022-01-06T17:13:21.385837Z"},"trusted":true},"outputs":[],"source":["img = cv2.imread('/kaggle/input/car-damage-detection/data1a/training/00-damage/0001.JPEG')\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:23.960051Z","iopub.status.busy":"2022-01-06T17:13:23.959753Z","iopub.status.idle":"2022-01-06T17:13:23.965495Z","shell.execute_reply":"2022-01-06T17:13:23.964775Z","shell.execute_reply.started":"2022-01-06T17:13:23.960018Z"},"trusted":true},"outputs":[],"source":["img.shape"]},{"cell_type":"markdown","metadata":{},"source":["### 1. Preprocessing and Augmentation\n","Data Augmentation is a technique used to create more data from existing ones by applying different kinds of transformations on it. Some of them applied here are:\n","- Rotation\n","- Horizontal flip\n","- Width and Height shifting\n","<br/><br/>"]},{"cell_type":"markdown","metadata":{},"source":["Some preprocessing done to the data are:\n","- Rescaling\n","- Feature-wise centering\n","- Sample-wise centering\n","This is done as the model used here (MobileNetV2) expects values between [-1,1]\n","An ImageDataGenerator is defined and points to the training and validation directories, which can be fed to the model to train."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:24.471533Z","iopub.status.busy":"2022-01-06T17:13:24.471046Z","iopub.status.idle":"2022-01-06T17:13:24.837112Z","shell.execute_reply":"2022-01-06T17:13:24.836270Z","shell.execute_reply.started":"2022-01-06T17:13:24.471495Z"},"trusted":true},"outputs":[],"source":["datagen = keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    rescale=2/255.0,\n","    featurewise_center=True, \n","    samplewise_center=True\n",")\n","\n","batch_size = 16\n","\n","train_datagen = datagen.flow_from_directory(\n","    directory='/kaggle/input/car-damage-detection/data1a/training',\n","    target_size=(256, 256),\n","    batch_size=batch_size,\n","    subset='training',\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    shuffle=True,\n","    seed=22\n",")\n","\n","validation_generator = datagen.flow_from_directory(\n","    directory='/kaggle/input/car-damage-detection/data1a/validation',\n","    target_size=(256, 256),\n","    batch_size=batch_size,\n","    subset='training',\n","    color_mode='rgb',\n","    class_mode='categorical',\n","    shuffle=True,\n","    seed=22\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Model Definition and Training\n","The model used here is a pre-trained MobileNetV2, and is fine-tuned using transfer learning. This seemed like a good way to approach the problem as it is generally more accurate."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:26.314516Z","iopub.status.busy":"2022-01-06T17:13:26.313803Z","iopub.status.idle":"2022-01-06T17:13:28.205584Z","shell.execute_reply":"2022-01-06T17:13:28.204848Z","shell.execute_reply.started":"2022-01-06T17:13:26.314477Z"},"trusted":true},"outputs":[],"source":["w, h, c = (256, 256, 3)\n","\n","mobilenet = keras.applications.MobileNetV2(\n","    input_shape=(w,h,c),\n","    pooling='avg',\n","    include_top=False,\n","    weights='imagenet',\n","    classes=2\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:33.598653Z","iopub.status.busy":"2022-01-06T17:13:33.598155Z","iopub.status.idle":"2022-01-06T17:13:33.601741Z","shell.execute_reply":"2022-01-06T17:13:33.601039Z","shell.execute_reply.started":"2022-01-06T17:13:33.598614Z"},"trusted":true},"outputs":[],"source":["# mobilenet.summary()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:38.572457Z","iopub.status.busy":"2022-01-06T17:13:38.571575Z","iopub.status.idle":"2022-01-06T17:13:38.579273Z","shell.execute_reply":"2022-01-06T17:13:38.578295Z","shell.execute_reply.started":"2022-01-06T17:13:38.572408Z"},"trusted":true},"outputs":[],"source":["len(mobilenet.layers)"]},{"cell_type":"markdown","metadata":{},"source":["The first few layers of the model are frozen (non-trainable). This is done for some reasons like:\n","- Reducing training complexity/time\n","- Reducing number of trainable parameters"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:40.068927Z","iopub.status.busy":"2022-01-06T17:13:40.068138Z","iopub.status.idle":"2022-01-06T17:13:40.147186Z","shell.execute_reply":"2022-01-06T17:13:40.146406Z","shell.execute_reply.started":"2022-01-06T17:13:40.068878Z"},"trusted":true},"outputs":[],"source":["# Total of 175 layers, set first 120 as non-trainable\n","for layer in mobilenet.layers[:110]:\n","    layer.trainable = False\n","\n","for layer in mobilenet.layers[110:]:\n","    layer.trainable = True\n","        \n","mobilenet.summary()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:40.990312Z","iopub.status.busy":"2022-01-06T17:13:40.989992Z","iopub.status.idle":"2022-01-06T17:13:41.441629Z","shell.execute_reply":"2022-01-06T17:13:41.440929Z","shell.execute_reply.started":"2022-01-06T17:13:40.990274Z"},"trusted":true},"outputs":[],"source":["model = keras.models.Sequential([\n","    mobilenet,\n","    keras.layers.Dense(512, activation=keras.activations.relu),\n","    keras.layers.Dense(128, activation=keras.activations.relu),\n","    keras.layers.Dense(2, activation=keras.activations.softmax)\n","])"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:13:43.696764Z","iopub.status.busy":"2022-01-06T17:13:43.695889Z","iopub.status.idle":"2022-01-06T17:13:43.716701Z","shell.execute_reply":"2022-01-06T17:13:43.715907Z","shell.execute_reply.started":"2022-01-06T17:13:43.696708Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:14:02.154621Z","iopub.status.busy":"2022-01-06T17:14:02.154370Z","iopub.status.idle":"2022-01-06T17:14:02.159557Z","shell.execute_reply":"2022-01-06T17:14:02.158783Z","shell.execute_reply.started":"2022-01-06T17:14:02.154592Z"},"trusted":true},"outputs":[],"source":["import os\n","print(os.getcwd())"]},{"cell_type":"markdown","metadata":{},"source":["The following callbacks are defined:\n","- Model checkpointing, for storing model weights after each epoch\n","- Early stopping with patience, to avoid overfitting"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:14:34.074453Z","iopub.status.busy":"2022-01-06T17:14:34.074161Z","iopub.status.idle":"2022-01-06T17:14:34.093120Z","shell.execute_reply":"2022-01-06T17:14:34.092374Z","shell.execute_reply.started":"2022-01-06T17:14:34.074423Z"},"trusted":true},"outputs":[],"source":["base_learning_rate = 0.0001\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n","              loss=tf.keras.losses.binary_crossentropy,\n","              metrics=['accuracy'])\n","\n","ckpt_path = os.path.join(os.getcwd(), 'checkpoint')\n","checkpoint = keras.callbacks.ModelCheckpoint(\n","    filepath=ckpt_path,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_freq='epoch'\n",")\n","\n","earlystopping = keras.callbacks.EarlyStopping(\n","    monitor='val_accuracy',\n","    patience=5,\n","    mode='max'\n",")\n","\n","callbacks = [checkpoint, earlystopping]"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:14:36.180759Z","iopub.status.busy":"2022-01-06T17:14:36.180087Z","iopub.status.idle":"2022-01-06T17:30:42.413958Z","shell.execute_reply":"2022-01-06T17:30:42.413190Z","shell.execute_reply.started":"2022-01-06T17:14:36.180712Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 50\n","\n","history = model.fit(\n","    train_datagen,\n","    validation_data=validation_generator,\n","    steps_per_epoch=train_datagen.n//train_datagen.batch_size,\n","    validation_steps=validation_generator.n//validation_generator.batch_size,\n","    epochs=EPOCHS,\n","    callbacks=callbacks\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Generally, the model is fine tuned by unfreezing the previously frozen layers and further decreasing the learning rate. Since this model consistently achived validation accuracies >90% without fine-tuning, it was not done.\n","<br/><br/>\n","After training, the model weights are saved in a directory ('./checkpoint') and is compressed into a zip file. A download link is generated that automatically downloads the file upon clicking."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:39:33.734590Z","iopub.status.busy":"2022-01-06T17:39:33.734297Z","iopub.status.idle":"2022-01-06T17:39:36.272998Z","shell.execute_reply":"2022-01-06T17:39:36.272145Z","shell.execute_reply.started":"2022-01-06T17:39:33.734558Z"},"trusted":true},"outputs":[],"source":["!zip -r file.zip {os.path.join(os.getcwd(), 'checkpoint')}"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-01-06T17:40:57.616853Z","iopub.status.busy":"2022-01-06T17:40:57.616130Z","iopub.status.idle":"2022-01-06T17:40:57.622866Z","shell.execute_reply":"2022-01-06T17:40:57.622043Z","shell.execute_reply.started":"2022-01-06T17:40:57.616809Z"},"trusted":true},"outputs":[],"source":["from IPython.display import FileLink\n","FileLink('./file.zip')"]},{"cell_type":"markdown","metadata":{},"source":["For convinience, the trained model's weights have been uploaded to GDrive and the link is provided below:\n","https://drive.google.com/drive/folders/15PDR5tNwqAQ6TobLVU6LRNhOVSN5RcCA?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
